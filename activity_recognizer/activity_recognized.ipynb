{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba3b1ff2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:52:16.596117Z",
          "iopub.status.busy": "2025-02-20T00:52:16.595780Z",
          "iopub.status.idle": "2025-02-20T00:52:16.725209Z",
          "shell.execute_reply": "2025-02-20T00:52:16.724132Z"
        },
        "id": "ba3b1ff2",
        "papermill": {
          "duration": 0.136278,
          "end_time": "2025-02-20T00:52:16.726461",
          "exception": true,
          "start_time": "2025-02-20T00:52:16.590183",
          "status": "failed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8388ced2-799d-4295-9b74-2ddeebd9667d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive; drive.mount('/content/drive')   # OK to enable, if your kaggle.json is stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f01f9e8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-19T22:16:49.060232Z",
          "iopub.status.busy": "2025-02-19T22:16:49.059940Z",
          "iopub.status.idle": "2025-02-19T22:16:54.890504Z",
          "shell.execute_reply": "2025-02-19T22:16:54.889632Z",
          "shell.execute_reply.started": "2025-02-19T22:16:49.060201Z"
        },
        "id": "6f01f9e8",
        "outputId": "6b9f39a0-da67-421a-873c-963b84e18764",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- competition is now set to: 6-feb-25-hse-har\n",
            "100% 601M/601M [00:04<00:00, 155MB/s]\n",
            "Using competition: 6-feb-25-hse-har\n",
            "  teamId  teamName              submissionDate       score    \n",
            "--------  --------------------  -------------------  -------  \n",
            "13317731  AH                    2025-02-17 14:01:20  0.98234  \n",
            "13308368  K🔫🔫                   2025-02-20 14:29:32  0.97895  \n",
            "13305124  D XX                  2025-02-20 13:37:15  0.97759  \n",
            "13309866  Q                     2025-02-20 14:29:55  0.97556  \n",
            "13330366  F                     2025-02-20 11:55:12  0.97216  \n",
            "13327034  A                     2025-02-20 06:08:09  0.97080  \n",
            "13318042  Z                     2025-02-19 16:35:09  0.96945  \n",
            "13313084  AA                    2025-02-20 11:56:09  0.96945  \n",
            "13308774  AG                    2025-02-20 05:27:02  0.96877  \n",
            "13319546  L                     2025-02-20 12:55:27  0.96673  \n",
            "13320317  С                     2025-02-18 21:28:39  0.96673  \n",
            "13316475  Team W                2025-02-20 13:39:51  0.96673  \n",
            "13316918  I                     2025-02-18 20:14:58  0.96605  \n",
            "13330667  T                     2025-02-19 16:49:10  0.96469  \n",
            "13327300  M                     2025-02-20 13:18:08  0.96334  \n",
            "13327512  P                     2025-02-20 07:51:35  0.96334  \n",
            "13327545  Y                     2025-02-20 13:15:22  0.96266  \n",
            "13330100  J                     2025-02-20 13:50:38  0.96198  \n",
            "13322444  AK                    2025-02-20 14:30:38  0.96198  \n",
            "13305903  AI                    2025-02-12 12:03:03  0.96130  \n",
            "13320280  H                     2025-02-14 15:42:13  0.95994  \n",
            "13306098  AJ                    2025-02-20 14:11:27  0.95994  \n",
            "13321151  OK Computer           2025-02-20 13:58:08  0.95926  \n",
            "13326685  ADoviy ADok           2025-02-20 12:53:39  0.95926  \n",
            "13326595  R                     2025-02-20 14:31:40  0.95926  \n",
            "13330092  AF                    2025-02-17 23:30:40  0.95790  \n",
            "13330642  G                     2025-02-20 14:13:47  0.95655  \n",
            "13326366  x                     2025-02-20 14:05:43  0.95587  \n",
            "13307950  V                     2025-02-20 12:05:47  0.95451  \n",
            "13325311  🏃AE ae                2025-02-20 12:21:37  0.95315  \n",
            "13375129  AM                    2025-02-20 12:25:02  0.95179  \n",
            "13321761  U                     2025-02-20 14:35:04  0.94976  \n",
            "13329669  AC                    2025-02-20 11:38:31  0.94840  \n",
            "13315892  S                     2025-02-20 13:45:51  0.94433  \n",
            "13330378  AB                    2025-02-12 13:33:14  0.94297  \n",
            "13326592  B                     2025-02-20 13:39:57  0.94093  \n",
            "13327756  E                     2025-02-16 18:17:36  0.94025  \n",
            "13329170  AN                    2025-02-12 12:30:31  0.92803  \n",
            "13330715  AL_real_AL            2025-02-12 14:15:05  0.92803  \n",
            "13310232  Alexander Der Grosse  2025-02-14 04:05:44  0.92532  \n",
            "13304863  Baseline              2025-02-06 15:44:23  0.92396  \n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n",
        "!mkdir -p ~/.kaggle                                           # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json > log                   # Alternative location of kaggle.json (without a connection to Google Drive)\n",
        "!chmod 600 ~/.kaggle/kaggle.json                              # give only the owner full read/write access to kaggle.json\n",
        "!kaggle config set -n competition -v 6-feb-25-hse-har           # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n",
        "!kaggle competitions download >> log                          # download competition dataset as a zip file\n",
        "!unzip -o *.zip >> log                                        # Kaggle dataset is copied as a single file and needs to be unzipped.\n",
        "!kaggle competitions leaderboard --show                       # print public leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dedd4b73",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-19T23:11:00.330864Z",
          "iopub.status.busy": "2025-02-19T23:11:00.330539Z",
          "iopub.status.idle": "2025-02-19T23:11:03.741966Z",
          "shell.execute_reply": "2025-02-19T23:11:03.741091Z",
          "shell.execute_reply.started": "2025-02-19T23:11:00.330841Z"
        },
        "id": "dedd4b73",
        "outputId": "ddce55e6-238f-4967-b64c-9b10f190b5e8",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.37 s, sys: 462 ms, total: 2.83 s\n",
            "Wall time: 5.82 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
        "import numpy as np, pandas as pd, time, os, random\n",
        "\n",
        "np.set_printoptions(linewidth=10000, precision=2, edgeitems=20, suppress=True)\n",
        "pd.set_option('display.max_colwidth', 1000, 'display.max_columns', 100, 'display.width', 1000, 'display.max_rows', 4)\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torchsummary import summary\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=60): self.t0, self.lim, _ = time.time(), lim, print(f'⏳ started. You have {lim} sec. Good luck!')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37073bbf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-19T23:11:14.109632Z",
          "iopub.status.busy": "2025-02-19T23:11:14.109177Z",
          "iopub.status.idle": "2025-02-19T23:11:14.119216Z",
          "shell.execute_reply": "2025-02-19T23:11:14.118514Z",
          "shell.execute_reply.started": "2025-02-19T23:11:14.109605Z"
        },
        "id": "37073bbf",
        "outputId": "d8722e2e-aec1-4b04-e196-acfbd2f3c78a",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 0\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c751b59",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-19T23:11:15.531997Z",
          "iopub.status.busy": "2025-02-19T23:11:15.531702Z",
          "iopub.status.idle": "2025-02-19T23:11:15.606213Z",
          "shell.execute_reply": "2025-02-19T23:11:15.605176Z",
          "shell.execute_reply.started": "2025-02-19T23:11:15.531975Z"
        },
        "id": "1c751b59",
        "outputId": "00b647dc-961e-4ce8-9be9-115c3c0458aa",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda activated\n"
          ]
        }
      ],
      "source": [
        "# Check if cuda activated.\n",
        "# If not, go to Runtime -> Change runtime type. Select 'T4 GPU'\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print('cuda activated')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('cpu activated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f102c138",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-19T23:11:17.261947Z",
          "iopub.status.busy": "2025-02-19T23:11:17.261631Z",
          "iopub.status.idle": "2025-02-19T23:12:19.527116Z",
          "shell.execute_reply": "2025-02-19T23:12:19.526208Z",
          "shell.execute_reply.started": "2025-02-19T23:11:17.261922Z"
        },
        "id": "f102c138",
        "outputId": "7cb2c7d1-bdfa-4647-f73a-7b998b9f0351",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 335 ms, sys: 28.4 ms, total: 363 ms\n",
            "Wall time: 464 ms\n",
            "CPU times: user 47.8 s, sys: 5.9 s, total: 53.7 s\n",
            "Wall time: 1min 8s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        y       0       1       2       3       4       5       6       7       8       9      10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31      32      33      34      35      36      37      38      39      40      41      42      43     44      45      46      47      48  ...     511     512     513     514     515     516     517     518     519     520    521     522     523     524     525     526     527     528     529     530     531    532     533    534     535     536     537     538     539     540     541     542     543     544     545     546     547     548     549    550     551     552     553     554     555     556     557     558     559     560\n",
              "0       5  0.2778  0.0092 -0.0676 -0.9785 -0.9160 -0.9610 -0.9834 -0.9170 -0.9590 -0.9390 -0.4230 -0.7520  0.8496  0.6226  0.8400 -0.9434 -0.9614 -1.0370 -1.0150 -1.0070 -0.9640 -0.9550 -0.6772  0.0568  0.0192  0.5900 -0.3162  0.1833  0.4440 -0.2622  0.1092  0.4468 -0.4443 -0.1484  0.1718 -0.2727  0.0954 -0.4720 -0.5264  0.2332  0.9640 -0.1309  0.1071 -0.9814 -0.948 -0.9727 -0.9720 -0.9575 -0.9585  ... -0.9126 -0.2037 -0.5300 -0.8164 -0.9170 -0.8850 -0.9033 -0.9120 -0.9750 -0.9326 -1.014 -0.9560 -0.6780 -0.9966 -0.6180 -0.1021 -0.5977 -0.9546 -0.9110 -0.9260 -0.9297 -1.017 -0.9460 -1.022 -0.9570 -0.2930 -1.0100 -0.3455 -0.1411 -0.5215 -0.9585 -0.9160 -0.9434 -0.9414 -0.9750 -0.9414 -0.9890 -0.9610 -0.4453 -1.002 -0.5415 -0.0308 -0.5093  0.0380 -0.0912 -0.1415 -0.1316 -0.8200  0.1721 -0.0535\n",
              "1       1  0.2454  0.0073 -0.1046 -0.2010  0.1426 -0.2668 -0.2776  0.0648 -0.2605 -0.0572 -0.0364 -0.2830 -0.2830 -0.1448  0.4443 -0.0844 -0.6733 -0.7603 -0.7847 -0.4136 -0.3633 -0.1837  0.2830  0.5100  0.0582 -0.2502  0.3079 -0.1384  0.0822  0.0902 -0.0034  0.1969  0.0538  0.2996 -0.0258  0.0936 -0.3472 -0.1434 -0.4058  0.3690  0.9326 -0.2942 -0.0916 -0.9966 -0.964 -0.9663 -0.9746 -0.9736 -0.9634  ... -0.8115  0.4165 -0.4731 -0.8210  0.2542  0.2410  0.2688  0.0928 -0.7710  0.2430 -0.221 -0.1018  0.7134 -0.8994 -0.0642 -0.0842 -0.4750 -0.1345 -0.3853 -0.2573 -0.5430 -0.757 -0.1365 -0.677 -0.1826  0.6777 -0.7866  0.3240 -0.6206 -0.8530 -0.2500 -0.3025 -0.3176 -0.3198 -0.6426 -0.2488 -0.7236 -0.2512  0.6177 -0.910  0.1069 -0.0397 -0.4220  0.5480  0.6455  0.2296 -0.0335 -0.7000  0.2998  0.0880\n",
              "...    ..     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...    ...     ...     ...     ...     ...  ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...    ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...    ...     ...    ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...    ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...\n",
              "499998  4  0.2740 -0.0132 -0.1257 -0.9834 -1.0020 -0.9590 -0.9897 -0.9746 -0.9873 -0.9346 -0.5630 -0.8394  0.8306  0.6846  0.8350 -0.9840 -0.9824 -0.9960 -1.0200 -0.9950 -1.0160 -0.9590 -0.6500 -0.5225 -0.7974  0.5020 -0.2532  0.3723  0.1772  0.2920 -0.2756  0.3179 -0.1398  0.0948  0.0180 -0.1853  0.1871  0.0790 -0.0402 -0.0880  0.9785 -0.0442 -0.0532 -0.9950 -1.028 -0.9790 -1.0010 -0.9697 -1.0060  ... -0.2356  0.4312 -0.6030 -0.8706 -0.9700 -0.9863 -1.0010 -0.9990 -0.9927 -0.9910 -1.020 -1.0210 -0.9920 -0.9736  0.3857 -0.4620 -0.7485 -0.9985 -0.9575 -0.9897 -0.9814 -1.000 -0.9990 -1.008 -0.9660 -0.8574 -0.9210  0.1049 -0.6284 -0.8970 -1.0200 -1.0150 -0.9750 -1.0170 -0.9746 -0.9937 -0.9927 -0.9950 -1.0030 -0.844  0.2454 -0.3782 -0.7183 -0.0227  0.1957  0.1864  0.4556 -0.9326  0.1137  0.0595\n",
              "499999  5  0.2695 -0.0251 -0.1010 -1.0170 -0.9050 -0.9375 -0.9736 -0.8920 -0.9673 -0.9575 -0.5293 -0.8022  0.8530  0.6714  0.8480 -0.9624 -1.0205 -0.9900 -0.9600 -0.9960 -0.9480 -0.9720 -0.7320 -0.5117 -0.3535  0.3710 -0.2270  0.2700 -0.0636 -0.2438  0.0608  0.2050 -0.0218 -0.1199  0.0678  0.0154 -0.1132 -0.2886 -0.3882  0.6284  0.9966 -0.1277  0.0722 -1.0050 -0.925 -0.9440 -1.0050 -0.9824 -0.9233  ... -0.9500  0.0488 -0.3591 -0.7050 -1.0240 -0.9790 -0.9746 -0.9814 -0.9920 -0.9814 -1.013 -0.9860 -0.9650 -1.0150 -0.1430 -0.1555 -0.5180 -0.9320 -0.9200 -0.9424 -0.9326 -0.932 -0.9170 -0.985 -0.9463 -0.4020 -0.9640 -0.3160 -0.0948 -0.4695 -0.9590 -0.9500 -0.9976 -0.9680 -1.0340 -0.9727 -0.9900 -0.9790 -0.6980 -1.017 -0.4863  0.0084 -0.3293 -0.0127 -0.1399  0.4624 -0.7610 -0.8696  0.1720 -0.0272\n",
              "\n",
              "[500000 rows x 562 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07d564da-0641-4ac6-b37e-87642a2dcedc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>...</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>524</th>\n",
              "      <th>525</th>\n",
              "      <th>526</th>\n",
              "      <th>527</th>\n",
              "      <th>528</th>\n",
              "      <th>529</th>\n",
              "      <th>530</th>\n",
              "      <th>531</th>\n",
              "      <th>532</th>\n",
              "      <th>533</th>\n",
              "      <th>534</th>\n",
              "      <th>535</th>\n",
              "      <th>536</th>\n",
              "      <th>537</th>\n",
              "      <th>538</th>\n",
              "      <th>539</th>\n",
              "      <th>540</th>\n",
              "      <th>541</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "      <th>555</th>\n",
              "      <th>556</th>\n",
              "      <th>557</th>\n",
              "      <th>558</th>\n",
              "      <th>559</th>\n",
              "      <th>560</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.2778</td>\n",
              "      <td>0.0092</td>\n",
              "      <td>-0.0676</td>\n",
              "      <td>-0.9785</td>\n",
              "      <td>-0.9160</td>\n",
              "      <td>-0.9610</td>\n",
              "      <td>-0.9834</td>\n",
              "      <td>-0.9170</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-0.9390</td>\n",
              "      <td>-0.4230</td>\n",
              "      <td>-0.7520</td>\n",
              "      <td>0.8496</td>\n",
              "      <td>0.6226</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>-0.9434</td>\n",
              "      <td>-0.9614</td>\n",
              "      <td>-1.0370</td>\n",
              "      <td>-1.0150</td>\n",
              "      <td>-1.0070</td>\n",
              "      <td>-0.9640</td>\n",
              "      <td>-0.9550</td>\n",
              "      <td>-0.6772</td>\n",
              "      <td>0.0568</td>\n",
              "      <td>0.0192</td>\n",
              "      <td>0.5900</td>\n",
              "      <td>-0.3162</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>0.4440</td>\n",
              "      <td>-0.2622</td>\n",
              "      <td>0.1092</td>\n",
              "      <td>0.4468</td>\n",
              "      <td>-0.4443</td>\n",
              "      <td>-0.1484</td>\n",
              "      <td>0.1718</td>\n",
              "      <td>-0.2727</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>-0.4720</td>\n",
              "      <td>-0.5264</td>\n",
              "      <td>0.2332</td>\n",
              "      <td>0.9640</td>\n",
              "      <td>-0.1309</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>-0.9814</td>\n",
              "      <td>-0.948</td>\n",
              "      <td>-0.9727</td>\n",
              "      <td>-0.9720</td>\n",
              "      <td>-0.9575</td>\n",
              "      <td>-0.9585</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.9126</td>\n",
              "      <td>-0.2037</td>\n",
              "      <td>-0.5300</td>\n",
              "      <td>-0.8164</td>\n",
              "      <td>-0.9170</td>\n",
              "      <td>-0.8850</td>\n",
              "      <td>-0.9033</td>\n",
              "      <td>-0.9120</td>\n",
              "      <td>-0.9750</td>\n",
              "      <td>-0.9326</td>\n",
              "      <td>-1.014</td>\n",
              "      <td>-0.9560</td>\n",
              "      <td>-0.6780</td>\n",
              "      <td>-0.9966</td>\n",
              "      <td>-0.6180</td>\n",
              "      <td>-0.1021</td>\n",
              "      <td>-0.5977</td>\n",
              "      <td>-0.9546</td>\n",
              "      <td>-0.9110</td>\n",
              "      <td>-0.9260</td>\n",
              "      <td>-0.9297</td>\n",
              "      <td>-1.017</td>\n",
              "      <td>-0.9460</td>\n",
              "      <td>-1.022</td>\n",
              "      <td>-0.9570</td>\n",
              "      <td>-0.2930</td>\n",
              "      <td>-1.0100</td>\n",
              "      <td>-0.3455</td>\n",
              "      <td>-0.1411</td>\n",
              "      <td>-0.5215</td>\n",
              "      <td>-0.9585</td>\n",
              "      <td>-0.9160</td>\n",
              "      <td>-0.9434</td>\n",
              "      <td>-0.9414</td>\n",
              "      <td>-0.9750</td>\n",
              "      <td>-0.9414</td>\n",
              "      <td>-0.9890</td>\n",
              "      <td>-0.9610</td>\n",
              "      <td>-0.4453</td>\n",
              "      <td>-1.002</td>\n",
              "      <td>-0.5415</td>\n",
              "      <td>-0.0308</td>\n",
              "      <td>-0.5093</td>\n",
              "      <td>0.0380</td>\n",
              "      <td>-0.0912</td>\n",
              "      <td>-0.1415</td>\n",
              "      <td>-0.1316</td>\n",
              "      <td>-0.8200</td>\n",
              "      <td>0.1721</td>\n",
              "      <td>-0.0535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.2454</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>-0.1046</td>\n",
              "      <td>-0.2010</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>-0.2668</td>\n",
              "      <td>-0.2776</td>\n",
              "      <td>0.0648</td>\n",
              "      <td>-0.2605</td>\n",
              "      <td>-0.0572</td>\n",
              "      <td>-0.0364</td>\n",
              "      <td>-0.2830</td>\n",
              "      <td>-0.2830</td>\n",
              "      <td>-0.1448</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>-0.0844</td>\n",
              "      <td>-0.6733</td>\n",
              "      <td>-0.7603</td>\n",
              "      <td>-0.7847</td>\n",
              "      <td>-0.4136</td>\n",
              "      <td>-0.3633</td>\n",
              "      <td>-0.1837</td>\n",
              "      <td>0.2830</td>\n",
              "      <td>0.5100</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>-0.2502</td>\n",
              "      <td>0.3079</td>\n",
              "      <td>-0.1384</td>\n",
              "      <td>0.0822</td>\n",
              "      <td>0.0902</td>\n",
              "      <td>-0.0034</td>\n",
              "      <td>0.1969</td>\n",
              "      <td>0.0538</td>\n",
              "      <td>0.2996</td>\n",
              "      <td>-0.0258</td>\n",
              "      <td>0.0936</td>\n",
              "      <td>-0.3472</td>\n",
              "      <td>-0.1434</td>\n",
              "      <td>-0.4058</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.9326</td>\n",
              "      <td>-0.2942</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.9966</td>\n",
              "      <td>-0.964</td>\n",
              "      <td>-0.9663</td>\n",
              "      <td>-0.9746</td>\n",
              "      <td>-0.9736</td>\n",
              "      <td>-0.9634</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.8115</td>\n",
              "      <td>0.4165</td>\n",
              "      <td>-0.4731</td>\n",
              "      <td>-0.8210</td>\n",
              "      <td>0.2542</td>\n",
              "      <td>0.2410</td>\n",
              "      <td>0.2688</td>\n",
              "      <td>0.0928</td>\n",
              "      <td>-0.7710</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.1018</td>\n",
              "      <td>0.7134</td>\n",
              "      <td>-0.8994</td>\n",
              "      <td>-0.0642</td>\n",
              "      <td>-0.0842</td>\n",
              "      <td>-0.4750</td>\n",
              "      <td>-0.1345</td>\n",
              "      <td>-0.3853</td>\n",
              "      <td>-0.2573</td>\n",
              "      <td>-0.5430</td>\n",
              "      <td>-0.757</td>\n",
              "      <td>-0.1365</td>\n",
              "      <td>-0.677</td>\n",
              "      <td>-0.1826</td>\n",
              "      <td>0.6777</td>\n",
              "      <td>-0.7866</td>\n",
              "      <td>0.3240</td>\n",
              "      <td>-0.6206</td>\n",
              "      <td>-0.8530</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>-0.3025</td>\n",
              "      <td>-0.3176</td>\n",
              "      <td>-0.3198</td>\n",
              "      <td>-0.6426</td>\n",
              "      <td>-0.2488</td>\n",
              "      <td>-0.7236</td>\n",
              "      <td>-0.2512</td>\n",
              "      <td>0.6177</td>\n",
              "      <td>-0.910</td>\n",
              "      <td>0.1069</td>\n",
              "      <td>-0.0397</td>\n",
              "      <td>-0.4220</td>\n",
              "      <td>0.5480</td>\n",
              "      <td>0.6455</td>\n",
              "      <td>0.2296</td>\n",
              "      <td>-0.0335</td>\n",
              "      <td>-0.7000</td>\n",
              "      <td>0.2998</td>\n",
              "      <td>0.0880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>4</td>\n",
              "      <td>0.2740</td>\n",
              "      <td>-0.0132</td>\n",
              "      <td>-0.1257</td>\n",
              "      <td>-0.9834</td>\n",
              "      <td>-1.0020</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-0.9897</td>\n",
              "      <td>-0.9746</td>\n",
              "      <td>-0.9873</td>\n",
              "      <td>-0.9346</td>\n",
              "      <td>-0.5630</td>\n",
              "      <td>-0.8394</td>\n",
              "      <td>0.8306</td>\n",
              "      <td>0.6846</td>\n",
              "      <td>0.8350</td>\n",
              "      <td>-0.9840</td>\n",
              "      <td>-0.9824</td>\n",
              "      <td>-0.9960</td>\n",
              "      <td>-1.0200</td>\n",
              "      <td>-0.9950</td>\n",
              "      <td>-1.0160</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-0.6500</td>\n",
              "      <td>-0.5225</td>\n",
              "      <td>-0.7974</td>\n",
              "      <td>0.5020</td>\n",
              "      <td>-0.2532</td>\n",
              "      <td>0.3723</td>\n",
              "      <td>0.1772</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>-0.2756</td>\n",
              "      <td>0.3179</td>\n",
              "      <td>-0.1398</td>\n",
              "      <td>0.0948</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>-0.1853</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.0790</td>\n",
              "      <td>-0.0402</td>\n",
              "      <td>-0.0880</td>\n",
              "      <td>0.9785</td>\n",
              "      <td>-0.0442</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>-0.9950</td>\n",
              "      <td>-1.028</td>\n",
              "      <td>-0.9790</td>\n",
              "      <td>-1.0010</td>\n",
              "      <td>-0.9697</td>\n",
              "      <td>-1.0060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2356</td>\n",
              "      <td>0.4312</td>\n",
              "      <td>-0.6030</td>\n",
              "      <td>-0.8706</td>\n",
              "      <td>-0.9700</td>\n",
              "      <td>-0.9863</td>\n",
              "      <td>-1.0010</td>\n",
              "      <td>-0.9990</td>\n",
              "      <td>-0.9927</td>\n",
              "      <td>-0.9910</td>\n",
              "      <td>-1.020</td>\n",
              "      <td>-1.0210</td>\n",
              "      <td>-0.9920</td>\n",
              "      <td>-0.9736</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>-0.4620</td>\n",
              "      <td>-0.7485</td>\n",
              "      <td>-0.9985</td>\n",
              "      <td>-0.9575</td>\n",
              "      <td>-0.9897</td>\n",
              "      <td>-0.9814</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-0.9990</td>\n",
              "      <td>-1.008</td>\n",
              "      <td>-0.9660</td>\n",
              "      <td>-0.8574</td>\n",
              "      <td>-0.9210</td>\n",
              "      <td>0.1049</td>\n",
              "      <td>-0.6284</td>\n",
              "      <td>-0.8970</td>\n",
              "      <td>-1.0200</td>\n",
              "      <td>-1.0150</td>\n",
              "      <td>-0.9750</td>\n",
              "      <td>-1.0170</td>\n",
              "      <td>-0.9746</td>\n",
              "      <td>-0.9937</td>\n",
              "      <td>-0.9927</td>\n",
              "      <td>-0.9950</td>\n",
              "      <td>-1.0030</td>\n",
              "      <td>-0.844</td>\n",
              "      <td>0.2454</td>\n",
              "      <td>-0.3782</td>\n",
              "      <td>-0.7183</td>\n",
              "      <td>-0.0227</td>\n",
              "      <td>0.1957</td>\n",
              "      <td>0.1864</td>\n",
              "      <td>0.4556</td>\n",
              "      <td>-0.9326</td>\n",
              "      <td>0.1137</td>\n",
              "      <td>0.0595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>5</td>\n",
              "      <td>0.2695</td>\n",
              "      <td>-0.0251</td>\n",
              "      <td>-0.1010</td>\n",
              "      <td>-1.0170</td>\n",
              "      <td>-0.9050</td>\n",
              "      <td>-0.9375</td>\n",
              "      <td>-0.9736</td>\n",
              "      <td>-0.8920</td>\n",
              "      <td>-0.9673</td>\n",
              "      <td>-0.9575</td>\n",
              "      <td>-0.5293</td>\n",
              "      <td>-0.8022</td>\n",
              "      <td>0.8530</td>\n",
              "      <td>0.6714</td>\n",
              "      <td>0.8480</td>\n",
              "      <td>-0.9624</td>\n",
              "      <td>-1.0205</td>\n",
              "      <td>-0.9900</td>\n",
              "      <td>-0.9600</td>\n",
              "      <td>-0.9960</td>\n",
              "      <td>-0.9480</td>\n",
              "      <td>-0.9720</td>\n",
              "      <td>-0.7320</td>\n",
              "      <td>-0.5117</td>\n",
              "      <td>-0.3535</td>\n",
              "      <td>0.3710</td>\n",
              "      <td>-0.2270</td>\n",
              "      <td>0.2700</td>\n",
              "      <td>-0.0636</td>\n",
              "      <td>-0.2438</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>-0.0218</td>\n",
              "      <td>-0.1199</td>\n",
              "      <td>0.0678</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>-0.1132</td>\n",
              "      <td>-0.2886</td>\n",
              "      <td>-0.3882</td>\n",
              "      <td>0.6284</td>\n",
              "      <td>0.9966</td>\n",
              "      <td>-0.1277</td>\n",
              "      <td>0.0722</td>\n",
              "      <td>-1.0050</td>\n",
              "      <td>-0.925</td>\n",
              "      <td>-0.9440</td>\n",
              "      <td>-1.0050</td>\n",
              "      <td>-0.9824</td>\n",
              "      <td>-0.9233</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.9500</td>\n",
              "      <td>0.0488</td>\n",
              "      <td>-0.3591</td>\n",
              "      <td>-0.7050</td>\n",
              "      <td>-1.0240</td>\n",
              "      <td>-0.9790</td>\n",
              "      <td>-0.9746</td>\n",
              "      <td>-0.9814</td>\n",
              "      <td>-0.9920</td>\n",
              "      <td>-0.9814</td>\n",
              "      <td>-1.013</td>\n",
              "      <td>-0.9860</td>\n",
              "      <td>-0.9650</td>\n",
              "      <td>-1.0150</td>\n",
              "      <td>-0.1430</td>\n",
              "      <td>-0.1555</td>\n",
              "      <td>-0.5180</td>\n",
              "      <td>-0.9320</td>\n",
              "      <td>-0.9200</td>\n",
              "      <td>-0.9424</td>\n",
              "      <td>-0.9326</td>\n",
              "      <td>-0.932</td>\n",
              "      <td>-0.9170</td>\n",
              "      <td>-0.985</td>\n",
              "      <td>-0.9463</td>\n",
              "      <td>-0.4020</td>\n",
              "      <td>-0.9640</td>\n",
              "      <td>-0.3160</td>\n",
              "      <td>-0.0948</td>\n",
              "      <td>-0.4695</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-0.9500</td>\n",
              "      <td>-0.9976</td>\n",
              "      <td>-0.9680</td>\n",
              "      <td>-1.0340</td>\n",
              "      <td>-0.9727</td>\n",
              "      <td>-0.9900</td>\n",
              "      <td>-0.9790</td>\n",
              "      <td>-0.6980</td>\n",
              "      <td>-1.017</td>\n",
              "      <td>-0.4863</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>-0.3293</td>\n",
              "      <td>-0.0127</td>\n",
              "      <td>-0.1399</td>\n",
              "      <td>0.4624</td>\n",
              "      <td>-0.7610</td>\n",
              "      <td>-0.8696</td>\n",
              "      <td>0.1720</td>\n",
              "      <td>-0.0272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500000 rows × 562 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07d564da-0641-4ac6-b37e-87642a2dcedc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07d564da-0641-4ac6-b37e-87642a2dcedc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07d564da-0641-4ac6-b37e-87642a2dcedc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cbacd90d-47a9-4bad-9974-6701feba06c9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cbacd90d-47a9-4bad-9974-6701feba06c9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cbacd90d-47a9-4bad-9974-6701feba06c9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_317b5e8a-9620-4f36-865e-5806420f71f9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tYX')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_317b5e8a-9620-4f36-865e-5806420f71f9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tYX');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tYX"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "%time vX  = pd.read_csv('testX.csv', index_col='id')  # load testing input features X (only)\n",
        "%time tYX = pd.read_csv('trainYX.csv')                # partially load training labels Y and input features X\n",
        "tYX  # 561 input features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a07fb962",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-19T23:15:20.015226Z",
          "iopub.status.busy": "2025-02-19T23:15:20.014936Z",
          "iopub.status.idle": "2025-02-19T23:15:20.028119Z",
          "shell.execute_reply": "2025-02-19T23:15:20.027340Z",
          "shell.execute_reply.started": "2025-02-19T23:15:20.015204Z"
        },
        "id": "a07fb962",
        "outputId": "92a141b5-820a-4ee9-f915-4aac20ff72fb",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y          5      1      3      4      2      6\n",
              "count  93667  83502  66901  87427  72554  95949"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72728639-e0fd-4e62-a182-5bdbc61d6f59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>y</th>\n",
              "      <th>5</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>2</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>93667</td>\n",
              "      <td>83502</td>\n",
              "      <td>66901</td>\n",
              "      <td>87427</td>\n",
              "      <td>72554</td>\n",
              "      <td>95949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72728639-e0fd-4e62-a182-5bdbc61d6f59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72728639-e0fd-4e62-a182-5bdbc61d6f59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72728639-e0fd-4e62-a182-5bdbc61d6f59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tYX\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 93667,\n        \"max\": 93667,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          93667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 83502,\n        \"max\": 83502,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          83502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 66901,\n        \"max\": 66901,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          66901\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 87427,\n        \"max\": 87427,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          87427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 72554,\n        \"max\": 72554,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          72554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 95949,\n        \"max\": 95949,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          95949\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tYX.y.value_counts(sort=False).to_frame().T  # counts of observations in each label category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdfb1c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:48:26.689981Z",
          "iopub.status.busy": "2025-02-20T00:48:26.689648Z",
          "iopub.status.idle": "2025-02-20T00:48:26.694559Z",
          "shell.execute_reply": "2025-02-20T00:48:26.693734Z",
          "shell.execute_reply.started": "2025-02-20T00:48:26.689959Z"
        },
        "id": "abdfb1c9",
        "outputId": "59d3bbdf-92b4-48df-ca81-1746b0765ab7",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ started. You have 60 sec. Good luck!\n"
          ]
        }
      ],
      "source": [
        "tmr = Timer() # runtime limit (in seconds). Add all of your code after the timer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ce95262",
      "metadata": {
        "id": "6ce95262",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "During the preprocessing it was tried to use PCA and and stratified sampling. the choice of the parameters was \"brutally\" bruteforced. The result was to have PCA that explains 0.9985 variance. Stratified sampling of 50k observations to train yeild to lower score all the time in comparison of just taking top 50k observations. Then it was evaluated that top 75k observations taken to train results in higher score and that was the final solution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea was to mainly work with hyperparameters of the model (namely the number of layers and neurons, PCA components, load batch size, the dropout ratio and the number of epochs).\n",
        "The number of neurons is justified by the number components of PCA = 321 (and then divide by two for each layer). It was all just manually working out evaluated by the kaggle accuracy score. We also tested the different optimizers, and the Adam optimizer converges most fastly. The final parameters are shown in the model&training cell."
      ],
      "metadata": {
        "id": "j6F13K6J0e4a"
      },
      "id": "j6F13K6J0e4a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335e2b36",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:48:26.708800Z",
          "iopub.status.busy": "2025-02-20T00:48:26.708585Z",
          "iopub.status.idle": "2025-02-20T00:48:26.714499Z",
          "shell.execute_reply": "2025-02-20T00:48:26.713646Z",
          "shell.execute_reply.started": "2025-02-20T00:48:26.708781Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "335e2b36",
        "outputId": "f8e82504-a2e4-4e52-e68c-1604fd57a306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ],
      "source": [
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4351c9c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:48:26.733969Z",
          "iopub.status.busy": "2025-02-20T00:48:26.733709Z",
          "iopub.status.idle": "2025-02-20T00:48:27.385985Z",
          "shell.execute_reply": "2025-02-20T00:48:27.385180Z",
          "shell.execute_reply.started": "2025-02-20T00:48:26.733949Z"
        },
        "id": "b4351c9c",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "tX, tY = tYX.drop('y', axis=1).head(75000), tYX.head(75000).y-1   # shift labels by -1 to range {0,1,2,3,4,5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4452c9f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:48:27.387387Z",
          "iopub.status.busy": "2025-02-20T00:48:27.387141Z",
          "iopub.status.idle": "2025-02-20T00:48:27.393373Z",
          "shell.execute_reply": "2025-02-20T00:48:27.392714Z",
          "shell.execute_reply.started": "2025-02-20T00:48:27.387366Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4452c9f",
        "outputId": "46cf1519-4767-48ff-e0ea-025ca3e9f95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ],
      "source": [
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed9432aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:48:27.395070Z",
          "iopub.status.busy": "2025-02-20T00:48:27.394858Z",
          "iopub.status.idle": "2025-02-20T00:49:16.775199Z",
          "shell.execute_reply": "2025-02-20T00:49:16.774275Z",
          "shell.execute_reply.started": "2025-02-20T00:48:27.395052Z"
        },
        "id": "ed9432aa",
        "outputId": "51beabf5-4043-42dd-e96a-9ce8a81a4a20",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 161]          51,842\n",
            "       BatchNorm1d-2                  [-1, 161]             322\n",
            "           Dropout-3                  [-1, 161]               0\n",
            "            Linear-4                   [-1, 81]          13,122\n",
            "       BatchNorm1d-5                   [-1, 81]             162\n",
            "           Dropout-6                   [-1, 81]               0\n",
            "            Linear-7                    [-1, 6]             492\n",
            "================================================================\n",
            "Total params: 65,940\n",
            "Trainable params: 65,940\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.25\n",
            "Estimated Total Size (MB): 0.26\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Epoch 1/15, Loss: 0.4657\n",
            "Validation Loss: 0.1208\n",
            "Accuracy: 98.4133%\n",
            "Epoch 2/15, Loss: 0.0746\n",
            "Validation Loss: 0.0494\n",
            "Accuracy: 99.1956%\n",
            "Epoch 3/15, Loss: 0.0362\n",
            "Validation Loss: 0.0285\n",
            "Accuracy: 99.4933%\n",
            "Epoch 4/15, Loss: 0.0205\n",
            "Validation Loss: 0.0158\n",
            "Accuracy: 99.7822%\n",
            "Epoch 5/15, Loss: 0.013\n",
            "Validation Loss: 0.0105\n",
            "Accuracy: 99.8711%\n",
            "Epoch 6/15, Loss: 0.0077\n",
            "Validation Loss: 0.0066\n",
            "Accuracy: 99.96%\n",
            "Epoch 7/15, Loss: 0.0057\n",
            "Validation Loss: 0.0049\n",
            "Accuracy: 99.9644%\n",
            "Epoch 8/15, Loss: 0.0041\n",
            "Validation Loss: 0.0038\n",
            "Accuracy: 99.9733%\n",
            "Epoch 9/15, Loss: 0.0031\n",
            "Validation Loss: 0.0027\n",
            "Accuracy: 99.9689%\n",
            "Epoch 10/15, Loss: 0.0027\n",
            "Validation Loss: 0.0021\n",
            "Accuracy: 99.9867%\n",
            "Epoch 11/15, Loss: 0.002\n",
            "Validation Loss: 0.002\n",
            "Accuracy: 99.96%\n",
            "Epoch 12/15, Loss: 0.0016\n",
            "Validation Loss: 0.0013\n",
            "Accuracy: 99.9911%\n",
            "Epoch 13/15, Loss: 0.0013\n",
            "Validation Loss: 0.0015\n",
            "Accuracy: 99.9778%\n",
            "Epoch 14/15, Loss: 0.001\n",
            "Validation Loss: 0.001\n",
            "Accuracy: 99.9911%\n",
            "Epoch 15/15, Loss: 0.0009\n",
            "Validation Loss: 0.0009\n",
            "Accuracy: 100.0%\n"
          ]
        }
      ],
      "source": [
        "# Define the PyTorch model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, 161)\n",
        "        self.bn1 = nn.BatchNorm1d(161)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc2 = nn.Linear(161, 81)\n",
        "        self.bn2 = nn.BatchNorm1d(81)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc3 = nn.Linear(81, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "#PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.9985)\n",
        "tX_pca = pca.fit_transform(tX.values)\n",
        "tX = pd.DataFrame(tX_pca)\n",
        "\n",
        "\n",
        "\n",
        "# Convert numpy arrays to torch tensors\n",
        "tX_tensor = torch.tensor(tX.values, dtype=torch.float32)\n",
        "tY_tensor = torch.tensor(tY.values, dtype=torch.long)\n",
        "\n",
        "# If using GPU\n",
        "tX_tensor = tX_tensor.to(device)\n",
        "tY_tensor = tY_tensor.to(device)\n",
        "\n",
        "# Create TensorDataset and split into train val sets\n",
        "dataset = TensorDataset(tX_tensor, tY_tensor)\n",
        "val_size = int(len(dataset) * 0.3)\n",
        "train_size = len(dataset) - val_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128)\n",
        "\n",
        "# Instantiate the model\n",
        "model = Model(input_size=tX.shape[1]).to(device)\n",
        "print(summary(model, input_size=(tX.shape[1],)))\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
        "# Training loop\n",
        "epochs = 15\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {np.round(running_loss/len(train_loader), 4)}\")\n",
        "\n",
        "    # Validation loop\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        print(f\"Validation Loss: {np.round(val_loss/len(val_loader), 4)}\")\n",
        "        print(f\"Accuracy: {np.round(100 * correct / total, 4)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9784e27d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:49:16.776667Z",
          "iopub.status.busy": "2025-02-20T00:49:16.776407Z",
          "iopub.status.idle": "2025-02-20T00:49:16.808211Z",
          "shell.execute_reply": "2025-02-20T00:49:16.807267Z",
          "shell.execute_reply.started": "2025-02-20T00:49:16.776647Z"
        },
        "id": "9784e27d",
        "outputId": "16a6309a-e318-49d9-f1fe-b66af4009307",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=321, out_features=161, bias=True)\n",
              "  (bn1): BatchNorm1d(161, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (fc2): Linear(in_features=161, out_features=81, bias=True)\n",
              "  (bn2): BatchNorm1d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout2): Dropout(p=0.2, inplace=False)\n",
              "  (fc3): Linear(in_features=81, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=321, out_features=161, bias=True)\n",
              "  (bn1): BatchNorm1d(161, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (fc2): Linear(in_features=161, out_features=81, bias=True)\n",
              "  (bn2): BatchNorm1d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout2): Dropout(p=0.2, inplace=False)\n",
              "  (fc3): Linear(in_features=81, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#PCA for\n",
        "vX_pca = pca.transform(vX.values)\n",
        "vX_tensor = torch.tensor(vX_pca, dtype=torch.float32)\n",
        "model.to('cuda')\n",
        "vX_tensor = vX_tensor.to('cuda')\n",
        "model.eval()\n",
        "\n",
        "# No need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    # Make predictions\n",
        "    predictions = model(vX_tensor)\n",
        "\n",
        "# If you need class probabilities, apply softmax\n",
        "probabilities = torch.softmax(predictions, dim=1)\n",
        "\n",
        "# To get the predicted class labels, get the index of the max log-probability\n",
        "predicted_labels = torch.max(probabilities, 1)[1]\n",
        "\n",
        "# Convert to numpy array if needed (for further processing in non-PyTorch code)\n",
        "probabilities_np = probabilities.cpu().numpy()\n",
        "predicted_labels_np = predicted_labels.cpu().numpy()\n",
        "\n",
        "# Now 'probabilities_np' holds class probabilities and 'predicted_labels_np' holds class predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761643d7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:49:16.809366Z",
          "iopub.status.busy": "2025-02-20T00:49:16.809088Z",
          "iopub.status.idle": "2025-02-20T00:49:16.825015Z",
          "shell.execute_reply": "2025-02-20T00:49:16.824088Z",
          "shell.execute_reply.started": "2025-02-20T00:49:16.809336Z"
        },
        "id": "761643d7",
        "outputId": "d0180c9d-b2c9-4cba-c86b-da49e17e0d06",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x78d03c23b210>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_34166_row0_col0, #T_34166_row1_col5, #T_34166_row2_col5 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_34166_row0_col1, #T_34166_row0_col2, #T_34166_row0_col3, #T_34166_row0_col4, #T_34166_row0_col5, #T_34166_row1_col0, #T_34166_row1_col1, #T_34166_row1_col2, #T_34166_row1_col3, #T_34166_row1_col4, #T_34166_row2_col0, #T_34166_row2_col1, #T_34166_row2_col2, #T_34166_row2_col3, #T_34166_row2_col4 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_34166\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_34166_level0_col0\" class=\"col_heading level0 col0\" >0/walking</th>\n",
              "      <th id=\"T_34166_level0_col1\" class=\"col_heading level0 col1\" >1/walking_upstairs</th>\n",
              "      <th id=\"T_34166_level0_col2\" class=\"col_heading level0 col2\" >2/walking_downstairs</th>\n",
              "      <th id=\"T_34166_level0_col3\" class=\"col_heading level0 col3\" >3/sitting</th>\n",
              "      <th id=\"T_34166_level0_col4\" class=\"col_heading level0 col4\" >4/standing</th>\n",
              "      <th id=\"T_34166_level0_col5\" class=\"col_heading level0 col5\" >5/laying</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_34166_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_34166_row0_col0\" class=\"data row0 col0\" >0.999630</td>\n",
              "      <td id=\"T_34166_row0_col1\" class=\"data row0 col1\" >0.000032</td>\n",
              "      <td id=\"T_34166_row0_col2\" class=\"data row0 col2\" >0.000225</td>\n",
              "      <td id=\"T_34166_row0_col3\" class=\"data row0 col3\" >0.000009</td>\n",
              "      <td id=\"T_34166_row0_col4\" class=\"data row0 col4\" >0.000011</td>\n",
              "      <td id=\"T_34166_row0_col5\" class=\"data row0 col5\" >0.000093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_34166_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_34166_row1_col0\" class=\"data row1 col0\" >0.000002</td>\n",
              "      <td id=\"T_34166_row1_col1\" class=\"data row1 col1\" >0.000002</td>\n",
              "      <td id=\"T_34166_row1_col2\" class=\"data row1 col2\" >0.000003</td>\n",
              "      <td id=\"T_34166_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
              "      <td id=\"T_34166_row1_col4\" class=\"data row1 col4\" >0.000002</td>\n",
              "      <td id=\"T_34166_row1_col5\" class=\"data row1 col5\" >0.999991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_34166_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_34166_row2_col0\" class=\"data row2 col0\" >0.000002</td>\n",
              "      <td id=\"T_34166_row2_col1\" class=\"data row2 col1\" >0.000002</td>\n",
              "      <td id=\"T_34166_row2_col2\" class=\"data row2 col2\" >0.000001</td>\n",
              "      <td id=\"T_34166_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
              "      <td id=\"T_34166_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
              "      <td id=\"T_34166_row2_col5\" class=\"data row2 col5\" >0.999995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "YLab = [f'{i}/{s}' for i, s in enumerate('walking walking_upstairs walking_downstairs sitting standing laying'.split())]  # column labels\n",
        "pd.DataFrame(probabilities_np[:3,:], columns=YLab).style.background_gradient(cmap='coolwarm', axis=1)  # display first few predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e52d3e42",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:49:16.826111Z",
          "iopub.status.busy": "2025-02-20T00:49:16.825887Z",
          "iopub.status.idle": "2025-02-20T00:49:16.830198Z",
          "shell.execute_reply": "2025-02-20T00:49:16.829508Z",
          "shell.execute_reply.started": "2025-02-20T00:49:16.826080Z"
        },
        "id": "e52d3e42",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame(predicted_labels_np + 1, columns=['y']) # labels are shifted to the initial state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9199a945",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:49:16.831599Z",
          "iopub.status.busy": "2025-02-20T00:49:16.831245Z",
          "iopub.status.idle": "2025-02-20T00:49:16.863488Z",
          "shell.execute_reply": "2025-02-20T00:49:16.862634Z",
          "shell.execute_reply.started": "2025-02-20T00:49:16.831564Z"
        },
        "id": "9199a945",
        "outputId": "143b703f-0ca4-44c1-b91a-f09593f474b4",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     10    11    12    13    14    15    16    17    18    19    20    21    22    23    24    25    26    27    28    29    30    31    32    33    34    35    36    37    38    39    40    41    42    43    44    45    46    47    48    49    ...  2897  2898  2899  2900  2901  2902  2903  2904  2905  2906  2907  2908  2909  2910  2911  2912  2913  2914  2915  2916  2917  2918  2919  2920  2921  2922  2923  2924  2925  2926  2927  2928  2929  2930  2931  2932  2933  2934  2935  2936  2937  2938  2939  2940  2941  2942  2943  2944  2945  2946\n",
              "y     1     6     6     2     1     6     2     6     1     5     6     3     6     5     1     5     3     2     2     2     2     3     4     2     5     1     4     5     5     5     3     3     2     3     3     3     5     5     6     5     3     5     6     6     6     2     2     1     6     3  ...     2     5     4     5     2     3     2     6     1     5     1     5     2     3     4     5     2     2     1     3     1     5     5     2     6     3     6     6     6     3     6     5     3     5     1     4     1     3     6     6     2     1     3     2     4     5     6     3     4     2\n",
              "\n",
              "[1 rows x 2947 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84fa0d10-0465-4ea9-a832-df54715c4195\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>...</th>\n",
              "      <th>2897</th>\n",
              "      <th>2898</th>\n",
              "      <th>2899</th>\n",
              "      <th>2900</th>\n",
              "      <th>2901</th>\n",
              "      <th>2902</th>\n",
              "      <th>2903</th>\n",
              "      <th>2904</th>\n",
              "      <th>2905</th>\n",
              "      <th>2906</th>\n",
              "      <th>2907</th>\n",
              "      <th>2908</th>\n",
              "      <th>2909</th>\n",
              "      <th>2910</th>\n",
              "      <th>2911</th>\n",
              "      <th>2912</th>\n",
              "      <th>2913</th>\n",
              "      <th>2914</th>\n",
              "      <th>2915</th>\n",
              "      <th>2916</th>\n",
              "      <th>2917</th>\n",
              "      <th>2918</th>\n",
              "      <th>2919</th>\n",
              "      <th>2920</th>\n",
              "      <th>2921</th>\n",
              "      <th>2922</th>\n",
              "      <th>2923</th>\n",
              "      <th>2924</th>\n",
              "      <th>2925</th>\n",
              "      <th>2926</th>\n",
              "      <th>2927</th>\n",
              "      <th>2928</th>\n",
              "      <th>2929</th>\n",
              "      <th>2930</th>\n",
              "      <th>2931</th>\n",
              "      <th>2932</th>\n",
              "      <th>2933</th>\n",
              "      <th>2934</th>\n",
              "      <th>2935</th>\n",
              "      <th>2936</th>\n",
              "      <th>2937</th>\n",
              "      <th>2938</th>\n",
              "      <th>2939</th>\n",
              "      <th>2940</th>\n",
              "      <th>2941</th>\n",
              "      <th>2942</th>\n",
              "      <th>2943</th>\n",
              "      <th>2944</th>\n",
              "      <th>2945</th>\n",
              "      <th>2946</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 2947 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84fa0d10-0465-4ea9-a832-df54715c4195')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84fa0d10-0465-4ea9-a832-df54715c4195 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84fa0d10-0465-4ea9-a832-df54715c4195');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "result.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f1f799",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:49:45.725976Z",
          "iopub.status.busy": "2025-02-20T00:49:45.725659Z",
          "iopub.status.idle": "2025-02-20T00:49:45.733023Z",
          "shell.execute_reply": "2025-02-20T00:49:45.732340Z",
          "shell.execute_reply.started": "2025-02-20T00:49:45.725949Z"
        },
        "id": "31f1f799",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#ToCSV(result, 't28 2dropout0.2 batchnorm1d64 161-81-6 28 epochs pca.9985 adamlr0.0002 load batch 128 75kobs')\n",
        "ToCSV(result, 'final5 15 epochs fin loss 0.0009')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915fa9bb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-20T00:49:16.874085Z",
          "iopub.status.busy": "2025-02-20T00:49:16.873850Z",
          "iopub.status.idle": "2025-02-20T00:49:16.885535Z",
          "shell.execute_reply": "2025-02-20T00:49:16.884868Z",
          "shell.execute_reply.started": "2025-02-20T00:49:16.874065Z"
        },
        "id": "915fa9bb",
        "outputId": "348f5e05-8c45-47a0-b86e-dc6531f8352d",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime is 34 sec\n"
          ]
        }
      ],
      "source": [
        "tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6648219,
          "sourceId": 10724347,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6648155,
          "sourceId": 10724265,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3.033793,
      "end_time": "2025-02-20T00:52:17.048868",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-02-20T00:52:14.015075",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}